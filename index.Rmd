---
title: "NYC"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### Descriptives 

### deep dive into that dataset

Regression without matching.

put % black, % white, % asian, % ELL, huge correlation plot

## think about the poverty vs. ENI, and if multicollinear


### add correlation plot, regression\

##other variables
If you  can find that from literature



```{r}
library(tidyverse)
school_wide <- read_csv("data/merged.csv")
ela_wide <- read_csv("raw/ela_wide (1).csv")
math_wide <- read_csv("raw/math_wide (1).csv")
## bring together
data <- merge(ela_wide, math_wide, by = "DBN")
data <- merge(data, school_wide, by = "DBN")
## small table
small <- data %>%
  select(DBN, `School Name`, class_option, `3 2019.y`, `4 2019.y`, `5 2019.y`,
         `3 2019.x`, `4 2019.x`, `5 2019.x`, `Total Enrollment`, `% Poverty`,`% Students with Disabilities`, `Economic Need Index`, borough, school_type) %>%
  mutate(GT_option = case_when(class_option %in% c("GT", "SC and GT") ~ "gifted option",
                               class_option %in% c("no option", "SC") ~ "no gifted option"),
         SC_option = case_when(class_option %in% c("SC", "SC and GT") ~ "SC option",
                               class_option %in% c("no option", "GT") ~ "no SC option"),
         treatment = ifelse(GT_option == "gifted option", 1, 0))

#### 
### STEP 2: Prevalence of the Option, Likelihood
####
percent <- function(x, digits = 2, format = "f", ...) {
  paste0(formatC(100 * x, format = format, digits = digits, ...), "%")
}
liklihood <- small %>% 
  group_by(borough) %>%
  mutate(total=n()) %>%
  group_by(class_option, borough) %>%
  summarise(n=n(),
            ratio = n/total) %>%
  mutate(percentage = percent(ratio)) %>%
  distinct() %>%
  select(class_option, borough, percentage, ratio, n) %>%
  arrange(borough)
liklihood$ratio2 <- percent(liklihood$ratio)
liklihood
library(viridis)
ggplot(data = liklihood, aes(fill = class_option, y = ratio,
                       x = borough , label = ratio2))+
  geom_bar(position = "dodge", stat = "identity") +
  theme(
    legend.position = "none",
    plot.title = element_text(size=11),
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    panel.background = element_rect(fill = 'white'),
    axis.text.x = element_text(face = "bold", size = 12),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  ) +
  scale_fill_viridis(discrete = TRUE, alpha=0.6) +
  scale_y_continuous(labels = scales::percent)+
  geom_text(size = 4, position=position_dodge(width=1), vjust=-1, hjust = .4)


#### 
### STEP 3: Distribution of Variables
####

#### JESS: FOCUS HERE
### Test Scores
small$`3 2019.y` <-gsub(",","",small$`3 2019.y`,fixed = TRUE)
small$`3 2019.x` <-gsub(",","",small$`3 2019.x`,fixed = TRUE)
# small$`3 2019.y` <- as.numeric(small$`3 2019.y`)
mean(small$`3 2019.y`)
library(tidyverse)
small<- small %>%
  group_by(treatment) %>%
  na.omit() %>%
  filter(`3 2019.y` != "s") 
small_object<- small %>%
  summarise(mean_third_math = mean(as.numeric(`3 2019.y`)),
            mean_third_ela = mean(as.numeric(`3 2019.x`)))
small_object                         
### NOTE: for our GT study, we are going to have to split by has GT, doesn't have GT,
## and group by SC and GT

table(small$GT_option)
# create binary of GT or not

### GT Option by Economic Need, Poverty, Enrollment
small%>%
  group_by(GT_option) %>%
  summarise(mean_ec = mean(`Economic Need Index`),
            mean_poverty = mean(`% Poverty`),
            total = mean(`Total Enrollment`))
small%>%
  group_by(SC_option) %>%
  summarise(mean_ec = mean(`Economic Need Index`),
            mean_poverty = mean(`% Poverty`),
            total = mean(`Total Enrollment`))

#### GT Option by Borough
### boroughs
small %>%
  group_by(borough, GT_option) %>%
  summarise(mean_ec = mean(`Economic Need Index`),
            mean_poverty = mean(`% Poverty`),
            total = mean(`Total Enrollment`))


### GT Option by School Type *** NOTE: Middle Schools again have the biggest difference
small %>%
  group_by(school_type, GT_option) %>%
  summarise(mean_ec = mean(`Economic Need Index`),
            mean_poverty = mean(`% Poverty`),
            total = mean(`Total Enrollment`))


### regression just for third grade, ELA and Math scores  PART 1: bunch of these



names(small)
mod <- lm(`3 2019.y` ~ treatment + `Economic Need Index` + `Total Enrollment`, data =small)
summary(mod)
table(small$treatment)
mod <- lm(`3 2019.x` ~ treatment, data =small)
summary(mod)

### matched
library(MatchIt)
school_nearest <- matchit(formula = treatment ~ `Economic Need Index` + `Total Enrollment` +`% Students with Disabilities`, 
                          data = small,
                          method = "nearest",
                          family = "binomial",
                          caliper = 0.25,
                          ratio = 6)

nearest_matched <- match.data(school_nearest)

model_n <- lm(`3 2019.x` ~ treatment, data = nearest_matched)
summary(model_n)


```


#Plot out NYC
```{r}
library(ggplot2)
library(ggmap)
library(dplyr)
library(tidyverse)
```

# import the latitude data

```{r}
X2019_2020_School_Point_Locations <- read_csv("raw/2019_-_2020_School_Point_Locations.csv")

### using the first column to identify school locations 
head(X2019_2020_School_Point_Locations)
```
```{r}
#filter out schools with GT option
merged <- read_csv("data/merged.csv")
head(merged)
nrow(merged)
merged_gf <- merged %>% filter(gifted == 1)
head(merged_gf)
```

```{r}
merged_combined <- na.omit(X2019_2020_School_Point_Locations %>% 
                         left_join(merged, by = c("Loc_Name"= "School Name")) %>%
                         select(c("the_geom","Loc_Name","DBN","borough","Economic Need Index","% Black","% White","% Students with Disabilities","% Poverty")))
head(merged_combined)

gf_combined <- na.omit(X2019_2020_School_Point_Locations %>% 
                         left_join(merged_gf, by = c("Loc_Name"= "School Name")) %>%
                         select(c("the_geom","Loc_Name","DBN","borough","Economic Need Index","% Black","% White","% Students with Disabilities","% Poverty")))

head(gf_combined)
```

```{r}
#change the_geom to separate columns of long and lat data
x <- str_extract(gf_combined$the_geom,"(?<=\\().*(?=\\))")
x <- unlist(strsplit(x," "))
```

```{r}
#Extract long+lat data
odd <- seq(1,201,2)
even <- seq(2,202,2)
long <- c()
lat <- c()

for (i in 1:101){
  long[i] <- x[odd[i]]
  lat[i] <- x[even[i]]
}
gf_combined$long <- as.numeric(long)
gf_combined$lat <- as.numeric(lat)
gf_combined
```

```{r}
#change the_geom to separate columns of long and lat data
y <- str_extract(merged_combined$the_geom,"(?<=\\().*(?=\\))")
y <- unlist(strsplit(y," "))

```

```{r}
#Extract long+lat data
odd <- seq(1,2205,2)
even <- seq(2,2206,2)
long <- c()
lat <- c()

for (i in 1:1105){
  long[i] <- y[odd[i]]
  lat[i] <- y[even[i]]
}
merged_combined$long <- as.numeric(long)
merged_combined$lat <- as.numeric(lat)
merged_combined
```

